name: Model Tuning (Adaptive Schedule)

on:
  schedule:
    # Early season (Nov-Dec): Twice weekly - Tuesday & Saturday at 6:00 AM UTC
    - cron: '0 6 * 11-12 2'  # Tuesdays in Nov-Dec
    - cron: '0 6 * 11-12 6'  # Saturdays in Nov-Dec
    # Regular season (Jan-Mar): Weekly - Sunday at 6:00 AM UTC
    - cron: '0 6 * 1-3 0'    # Sundays in Jan-Mar
  push:
    branches: [main]
    paths:
      - '.github/workflows/weekly-tuning.yml'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write

jobs:
  tune-model:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      PYTHONPATH: ${{ github.workspace }}
    concurrency:
      group: ncaa-prediction-schedule
      cancel-in-progress: false
    
    steps:
    - name: Checkout repository (full history for hash comparisons)
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Backup current model params
      run: |
        if [ -f config/model_params.json ]; then
          cp config/model_params.json config/model_params.backup.json
          echo "Backed up model_params.json"
        fi

    - name: Detect training & config changes
      id: data_check
      run: |
        python scripts/check_training_data_change.py >> $GITHUB_OUTPUT
        echo "Detection summary:"
        cat $GITHUB_OUTPUT
    
    - name: Run weekly model tuning
      id: tuning
      if: steps.data_check.outputs.tune_needed == 'true'
      run: |
        python3 model_training/tune_model.py 2>&1 | tee tuning_output.log

    - name: Run calibration comparison
      if: steps.data_check.outputs.tune_needed == 'true'
      run: |
        python3 scripts/calibration_comparison.py 2>&1 | tee -a tuning_output.log

    - name: Upload tuning log on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: tuning-failure-log-${{ github.run_id }}
        path: |
          tuning_output.log
          config/model_params.backup.json
        retention-days: 7

    - name: Commit tuning & calibration results
      if: steps.data_check.outputs.tune_needed == 'true'
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add -A
        if git diff --cached --quiet; then
          echo "No changes detected after tuning; nothing to commit."
          exit 0
        fi
        git commit -m "Weekly model tuning & calibration - $(date +'%Y-%m-%d')"
        git pull --rebase --autostash origin main
        git push origin HEAD:main

    - name: Skip notice (no data changes)
      if: steps.data_check.outputs.tune_needed == 'false'
      run: |
        echo "No training/config changes detected; skipping tuning and calibration. Reasons: ${{ steps.data_check.outputs.tune_reasons }}"
